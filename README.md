# ğŸ¯ Competitor Hunter

> **AI-Powered Competitor Analysis Agent** | Automated web scraping and structured data extraction using MCP, LangGraph, and Playwright

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**Language | è¯­è¨€**: [English](README.md) | [ä¸­æ–‡](README.zh.md)

---

## ğŸ“– Introduction

**Competitor Hunter** is a production-ready AI agent that automates competitor analysis by scraping product pages and extracting structured information using Large Language Models. Built on the **Model Context Protocol (MCP)**, it seamlessly integrates with Claude Desktop and other MCP-compatible clients.

### Key Capabilities

- ğŸ” **Intelligent Web Scraping**: Automated browser-based content extraction with anti-detection features
- ğŸ¤– **LLM-Powered Extraction**: Structured data extraction using OpenAI-compatible APIs
- ğŸ“Š **Structured Output**: Pydantic-validated product information (pricing, features, SWOT analysis)
- ğŸ”„ **LangGraph Workflow**: Robust state management and error handling
- ğŸ”Œ **MCP Integration**: Native support for Claude Desktop and MCP clients

---

## ğŸ—ï¸ Architecture

The system follows **Hexagonal Architecture** with clear separation of concerns. Workflow: User Request â†’ MCP Server â†’ LangGraph Workflow â†’ Browser Scraping â†’ LLM Extraction â†’ Structured Data Response.

---

## âœ¨ Core Features

- **ğŸ¤– AI-Powered**: Intelligent extraction using LLM with automatic SWOT analysis
- **ğŸ“Š Structured Output**: Pydantic-validated data models (pricing, features, summary)
- **ğŸ›¡ï¸ Anti-Detection**: Random User-Agents, intelligent scrolling, auto-screenshots
- **ğŸ”Œ MCP Native**: Seamless integration with Claude Desktop and Cursor IDE
- **ğŸ“¦ CLI Tool**: Professional command-line interface via `competitor-hunter` command
- **Async/Await**: Full asynchronous programming for optimal performance

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+** (3.11 or 3.12 recommended)
- **UV** or **Poetry** (dependency manager)
- **Playwright** browsers (installed automatically)

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-username/competitor-hunter.git
   cd competitor-hunter
   ```

2. **Install dependencies** (using UV):
   ```bash
   uv sync
   ```

   Or using Poetry:
   ```bash
   poetry install
   ```

   Or using pip:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -e ".[dev]"
   ```

3. **Install Playwright browsers**:
   ```bash
   playwright install chromium
   ```

### Configuration

Create a `.env` file in the project root:

```bash
# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: for custom endpoints
OPENAI_MODEL_NAME=gpt-4o                    # Optional: default is gpt-4o

# Browser Configuration
HEADLESS_MODE=true                          # Set to false for debugging

# Database Configuration
DB_PATH=data/competitors.db                 # SQLite database path
```

> ğŸ’¡ **Tip**: Copy `.env.example` to `.env` and fill in your values:
> ```bash
cp .env.example .env
```

---

## ğŸ“¸ Screenshots & Examples

### Analysis Results

![Notion Pricing Analysis](docs/images/notion-pricing-analysis.png)
*Screenshot of Notion pricing page analysis*

### CLI Output Example

```bash
$ competitor-hunter https://www.notion.so/pricing
ğŸ” æ­£åœ¨åˆ†æ: https://www.notion.so/pricing

âœ… åˆ†æå®Œæˆï¼

======================================================================
ğŸ“¦ äº§å“åç§°: Notion
ğŸ”— URL: https://www.notion.so/pricing
ğŸ•’ æ›´æ–°æ—¶é—´: 2024-06-13 00:00:00+00:00
======================================================================

ğŸ’° å®šä»·æ–¹æ¡ˆ (4 ä¸ª):
   â€¢ Free: 0 USD / monthly
   â€¢ Plus: 10 USD / monthly
   â€¢ Business: 20 USD / monthly
   â€¢ Enterprise: Custom USD / custom

âœ¨ æ ¸å¿ƒåŠŸèƒ½ (13 ä¸ª):
   1. AI automation
   2. Enterprise search
   3. Meeting notes
   ...

ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: reports/product_Notion.json
```

### JSON Output Structure

The analysis results are saved as structured JSON files:

```json
{
  "product_name": "Notion",
  "url": "https://www.notion.so/pricing",
  "pricing_tiers": [
    {
      "name": "Free",
      "price": "0",
      "currency": "USD",
      "billing_cycle": "monthly"
    },
    {
      "name": "Plus",
      "price": "10",
      "currency": "USD",
      "billing_cycle": "monthly"
    }
  ],
  "core_features": [
    "AI automation",
    "Docs",
    "Knowledge Base"
  ],
  "summary": "## äº§å“æ¦‚è¿°\nNotion æ˜¯ä¸€æ¬¾é›†æ–‡æ¡£ç¼–è¾‘...",
  "last_updated": "2024-06-13T00:00:00Z"
}
```

---

## ğŸ“š Usage

### Method 1: CLI Command (Easiest)

After installation, use the `competitor-hunter` command:

```bash
# Analyze a single website
competitor-hunter https://www.notion.so/pricing

# Specify output file
competitor-hunter https://example.com output.json

# Batch analysis
competitor-hunter https://site1.com https://site2.com https://site3.com
```

Results are automatically saved to the `reports/` directory with proper UTF-8 encoding.

### Method 2: MCP Server Mode (Recommended for AI Assistants)

Run the MCP server to enable integration with Claude Desktop or Cursor:

```bash
python -m src.competitor_hunter.interface.mcp_server.server
```

#### Claude Desktop Integration

Add the following configuration to your Claude Desktop `claude_desktop_config.json`:

**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`  
**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`

```json
{
  "mcpServers": {
    "competitor-hunter": {
      "command": "python",
      "args": [
        "-m",
        "src.competitor_hunter.interface.mcp_server.server"
      ],
      "cwd": "/path/to/competitor-hunter"
    }
  }
}
```

#### Cursor IDE Integration

Create `.cursor/mcp.json` in your project root:

```json
{
  "mcpServers": {
    "competitor-hunter": {
      "command": "python",
      "args": [
        "-m",
        "src.competitor_hunter.interface.mcp_server.server"
      ],
      "cwd": "${workspaceFolder}"
    }
  }
}
```

After restarting, you can use the tool directly in chat:

```
Analyze this competitor: https://www.notion.so/pricing
```

### Method 3: Python Library

Use the LangGraph workflow directly in your Python code:

```python
import asyncio
from competitor_hunter.core import graph, AgentState, cleanup_resources

async def analyze(url: str):
    # Initialize state
    initial_state: AgentState = {
        "url": url,
        "scraped_content": None,
        "product": None,
        "error": None,
    }
    
    # Run workflow
    result = await graph.ainvoke(initial_state)
    
    # Check results
    if result.get("error"):
        print(f"Error: {result['error']}")
        return None
    
    product = result["product"]
    print(f"Product: {product.product_name}")
    print(f"Pricing Tiers: {len(product.pricing_tiers)}")
    print(f"Features: {product.core_features}")
    
    return product

# Use
product = await analyze("https://www.notion.so/pricing")
await cleanup_resources()
```

### Output Structure

All analysis results are saved to the `reports/` directory:

```
reports/
â”œâ”€â”€ product_Notion.json
â”œâ”€â”€ product_Example_Domain.json
â””â”€â”€ ...
```

Each JSON file contains:
- Product name and URL
- Pricing tiers (name, price, currency, billing cycle)
- Core features list
- Markdown-formatted summary with SWOT analysis
- Last updated timestamp

---

## ğŸ§ª Development

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_crawler.py -v

# Run with coverage
pytest tests/ --cov=src/competitor_hunter --cov-report=html
```

### Code Quality

```bash
# Format code
black src/ tests/

# Lint code
ruff check src/ tests/

# Type checking (if using mypy)
mypy src/
```

### Project Structure

```
competitor-hunter/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ competitor_hunter/
â”‚       â”œâ”€â”€ cli.py             # CLI command-line interface
â”‚       â”œâ”€â”€ main.py            # Application entry point
â”‚       â”œâ”€â”€ config.py          # Configuration management
â”‚       â”œâ”€â”€ core/               # Domain models & LangGraph workflow
â”‚       â”‚   â”œâ”€â”€ models.py       # Pydantic models (CompetitorProduct, etc.)
â”‚       â”‚   â””â”€â”€ graph.py        # LangGraph workflow definition
â”‚       â”œâ”€â”€ infrastructure/     # External services
â”‚       â”‚   â”œâ”€â”€ browser/        # Playwright browser service
â”‚       â”‚   â””â”€â”€ llm/            # LLM extractor service
â”‚       â””â”€â”€ interface/          # Entry points
â”‚           â””â”€â”€ mcp_server/     # MCP server implementation
â”œâ”€â”€ config/                     # Configuration files
â”‚   â””â”€â”€ app.yaml.example        # Configuration template
â”œâ”€â”€ docker/                     # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile              # Docker image definition
â”‚   â””â”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ examples/                   # Example scripts
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ reports/                    # Analysis results (gitignored)
â”œâ”€â”€ data/                       # SQLite database (gitignored)
â”œâ”€â”€ logs/                       # Screenshots & logs (gitignored)
â”œâ”€â”€ pyproject.toml              # Project dependencies & CLI entry points
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“¦ Dependencies

### Core Dependencies

- **mcp**: Model Context Protocol server implementation
- **langgraph**: Workflow orchestration
- **langchain**: LLM integration framework
- **playwright**: Browser automation
- **pydantic**: Data validation and serialization
- **html2text**: HTML to Markdown conversion
- **loguru**: Structured logging

### Development Dependencies

- **pytest**: Testing framework
- **pytest-asyncio**: Async test support
- **ruff**: Fast Python linter
- **black**: Code formatter

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph) for workflow orchestration
- Powered by [Playwright](https://playwright.dev/) for browser automation
- Integrated with [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for AI agent communication

---

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on [GitHub](https://github.com/your-username/competitor-hunter/issues).

---

**Made with â¤ï¸ for competitive intelligence**
